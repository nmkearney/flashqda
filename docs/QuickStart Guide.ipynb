{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b09b66c-d288-452b-ac97-426021b612a8",
   "metadata": {},
   "source": [
    "To install:\n",
    "\n",
    "1. Open Terminal.\n",
    "2. Type: python3 -m pip install flashqda\n",
    "\n",
    "FlashQDA currently offers four main functions:\n",
    "\n",
    "screen_abstracts: Provide a comma-separated list (.csv file) of abstracts and criteria for labelling them. For each abstract, FlashQDA returns whether the label applied to the abstract. Results are returned in a csv file to the Results folder. Place the list of abstracts within the Data folder. The abstracts should be listed down the first column (one abstract per cell), with the first row as the header, \"Abstract\". The criteria are passed to FlashQDA with your function call (see example below).\n",
    "\n",
    "preprocess_documents: Provide a set of plain text files (.txt). FlashQDA segments each document into a list of sentences. Results are returned in a csv file to the Results folder. Place the files within the Data folder.\n",
    "\n",
    "analyze_sentences: Provide a comma-separated list (.csv file) of sentences and choose among four analysis types: relationships_classify, tenses, list_of_terms, and relationships_extract:\n",
    "\n",
    "- relationships_classify classifies the relationships expressed within a sentence as causal, correlational, or none.\n",
    "- tenses lists the tenses used in the sentence.\n",
    "- list_of_terms checks the sentence for whether it contains items on a user-specified list of terms (provided with the function call).\n",
    "- relationships_extract retrieves cause/effect pairs from sentences (a sentence can yield multiple pairs).\n",
    "\n",
    "compare_concepts (Not documented here; coming soon): Provide a set of cause/effect pairs  (.csv file) of concepts and compare them for semantic similarity. Results are returned in a .csv file to the Results folder as a triangular matrix.\n",
    "\n",
    "In lieu of a user guide (in preparation), the notebook below provides examples of how to use the functions. Additional details on the functions are provided with the examples.\n",
    "\n",
    "FlashQDA is currently designed to work with OpenAI's API (GPT-4o). If you have not done so already, you will need to setup an account with OpenAI and obtain an API. There is a cost for using the API.\n",
    "\n",
    "The example uses two abstracts related to agroforestry in Peru, available in the Docs folder on GitHub (https://github.com/nmkearney/flashqda). Download the files and, once you have initialize your project (see below), add them to the Data folder. The files you need for the examples are:\n",
    "\n",
    "- abstracts.csv\n",
    "- Lojka et al. 2016\n",
    "- Ocampo-Ariza et al. 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b350eb-615b-4faa-8435-64f91f08a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flashqda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4318e9-1879-42a0-a558-f325ab046e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store your OpenAI API key\n",
    "import os\n",
    "#os.environ['OPENAI_API_KEY'] = '<YOUR_API_KEY>' # Uncomment and replace with your OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94335546-1702-4131-9451-2f21c91de078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a project\n",
    "directory = '/Users/<user_name>/Documents/MyProject' # Replace with the directory you want to use\n",
    "flashqda.initialize_project(directory) \n",
    "\n",
    "# initialize_project sets up the project folder and required subfolders (Data, Results).\n",
    "# It also changes the working directory to <directory>.\n",
    "# If you change the working directory (e.g., for another project), FlashQDA will stop working correctly.\n",
    "# You can set the working directory back to <directory> using: os.chdir(directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a006322-9adb-4653-9cb1-82b630ca632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screen abstracts example\n",
    "file_name = \"abstracts.csv\" # The name of the file that contains the abstracts (place it within the Data folder)\n",
    "criteria = [\"agroforestry is a main topic\",\n",
    "            \"slash-and-burn farming is a main topic\",\n",
    "            \"cacao yield is a main topic\",\n",
    "            \"experimental methods were used\"]\n",
    "flashqda.screen_abstracts(file_name, criteria)\n",
    "\n",
    "# screen_abstracts iterates over the list of abstracts and checks each criterion for whether it applies to the abstract.\n",
    "# By default, screen_abstracts checks each abstract/criterion pair 3 times and reports the % of positive test results.\n",
    "# You can modify the query count using the query_count argument. For example: screen_abstracts(file_name, criteria, query_count = 5).\n",
    "# Items in the criteria list must be enclosed by quotation marks and separated by commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7d5ee-52e8-42d6-ad8b-b0c1de256c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess documents example\n",
    "custom_items = [] # Empty by default\n",
    "save_name = 'analysis_1' # Name of the file where you want the sentences to be stored (will be placed within the Results subfolder)\n",
    "flashqda.preprocess_documents(save_name, custom_items)\n",
    "\n",
    "# preprocess_documents takes a set of plain text files and splits each into a list of sentences.\n",
    "# Each document is assigned a document ID, and each sentence is assigned a sentence ID.\n",
    "# Sentence splitting can be tricky. Sometimes sentences are split at unwanted places.\n",
    "# A set of rules is used to identify common sentence starts and ends.\n",
    "# For example, periods often (but not always!) mark sentence boundaries.\n",
    "# FlashQDA anticipates common sentence-splitting issues (e.g., abbreviations, such as \"Ms.\" and \"Dr.\").\n",
    "# After running preprocess_documents, you may notice cases of unwanted sentence splitting.\n",
    "# Identify the causes (e.g., the abbreviation \"spp.\" for \"species\") and add the special cases to the custom_items list.\n",
    "# Items in the list must be enclosed by quotation marks and separated by commas.\n",
    "# For example: custom_items = ['spp.', 'B.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bfaa0-a9cf-4b5a-ae78-f6d17aef9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentences example #1\n",
    "\n",
    "save_name = 'analysis_1' # Name of the document containing the list of (preprocessed) sentences\n",
    "analysis_type = 'relationships_classify' # The type of the current analysis\n",
    "context_length = 1 # The number of sentences prior to the focal sentence to be used as context for the focal sentence\n",
    "subscore_basis = ['causal'] # The categor(y|ies) used later for filtering\n",
    "filter = None # Not needed on the first analysis; see example #2 below\n",
    "filter_cutoff = 0 # Not needed on the first analysis; see exmple #2 example below\n",
    "\n",
    "sentences = flashqda.read_csv_file(save_name) # Sentences used in the analysis.\n",
    "flashqda.analyze_sentences(sentences=sentences,\n",
    "                              save_name=save_name,\n",
    "                              analysis_type=analysis_type,\n",
    "                              context_length=context_length, \n",
    "                              subscore_basis=subscore_basis,\n",
    "                              filter=filter,\n",
    "                              filter_cutoff=filter_cutoff)\n",
    "\n",
    "# analyze_all_sentences iterates over the list of sentences and applies the specified analysis type.\n",
    "# relationships_classify analyzes a sentence for whether it expresses any causal or correlational relationships.\n",
    "# If none are found, 'None' is reported.\n",
    "# By default, relationships_classify, tenses, and relationships_extract have a query_count of 3.\n",
    "# You can modify the query count using the query_count argument. For example, analyze_all_sentences(sentences, ..., query_count = 5).\n",
    "\n",
    "# context_length is helpful when causal relationships are expressed over more than one sentence (which is common).\n",
    "# By default, context_length = 0, but in many cases a context_lenght of 1 is helpful for detecting (and extracting) relationships.\n",
    "\n",
    "# subscore_basis is used to create a subscore, which is compared against filter_cutoff when a filter is used.\n",
    "# For example, subscore_basis = ['causal'] will report the proportion of times GPT decided the sentence expressed a causal relationship.\n",
    "# The proportion is equal to (frequency of category / number of decisions for sentence).\n",
    "# Items in the subscore_basis list must be enclosed by quotation marks and separated by commas.\n",
    "\n",
    "# filter is used to skip sentences that do not meet a user-specified cutoff.\n",
    "# For example, you may only want to further analyze (e.g., extract causal relationships) sentences that GPT decided expressed at least\n",
    "# one causal relationship. Then you would use the 'causal_relationships' filter with a filter_cutoff of, for example, 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c48de6-e40a-4d7d-b9c7-cb1e314892af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentences example #2\n",
    "\n",
    "save_name = 'analysis_1' # Same file as in the above example\n",
    "analysis_type = 'tenses'\n",
    "context_length = 0\n",
    "subscore_basis = ['simple present']\n",
    "filter = 'relationships_classify'\n",
    "filter_cutoff = 0.01\n",
    "\n",
    "sentences = flashqda.read_csv_file(save_name) # Sentences used in the analysis.\n",
    "flashqda.analyze_sentences(sentences=sentences, \n",
    "                              save_name=save_name,\n",
    "                              analysis_type=analysis_type,\n",
    "                              context_length=context_length, \n",
    "                              subscore_basis=subscore_basis,\n",
    "                              filter=filter,\n",
    "                              filter_cutoff=filter_cutoff)\n",
    "\n",
    "# You can run this analysis on top of the previous one. The analysis_1.csv file will be safely overwritten with the new information.\n",
    "# Only sentences that GPT decided expressed at least one causal relationship will be analyzed for the tenses used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c004823e-9b55-4b3f-83e9-3f193e8ede16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analyze sentences example #3\n",
    "\n",
    "save_name = 'analysis_2' # Create a new list of sentences\n",
    "flashqda.preprocess_documents(save_name)\n",
    "\n",
    "analysis_type = ['relationships_classify', \n",
    "             'tenses', \n",
    "             'list_of_terms',\n",
    "             'relationships_extract']\n",
    "context_length = [1,\n",
    "                  0,\n",
    "                  0,\n",
    "                  1]\n",
    "terms_to_check = [\n",
    "    [],\n",
    "    [],\n",
    "    ['suggest', ],\n",
    "    []\n",
    "]\n",
    "subscore_basis = [\n",
    "    ['causal'],\n",
    "    ['simple present'],\n",
    "    ['simple_present'],\n",
    "    ['simple_present']\n",
    "]\n",
    "filter = [None, \n",
    "          'relationships_classify', \n",
    "          'tenses',\n",
    "          'tenses']\n",
    "filter_cutoff = [0,\n",
    "                 0.1,\n",
    "                 0.1,\n",
    "                 0.1]\n",
    "\n",
    "for i in range(len(analysis_type)):\n",
    "    sentences = flashqda.read_csv_file(save_name)\n",
    "    flashqda.analyze_sentences(sentences=sentences,\n",
    "                                  save_name=save_name,\n",
    "                                  analysis_type=analysis_type[i], \n",
    "                                  context_length=context_length[i], \n",
    "                                  terms_to_check=terms_to_check[i],\n",
    "                                  subscore_basis=subscore_basis[i],\n",
    "                                  filter=filter[i],\n",
    "                                  filter_cutoff=filter_cutoff[i], \n",
    "                                  )\n",
    "\n",
    "# This loop will run four analyses in sequence.\n",
    "# If it is interrupted (you can hit the stop button in Jupyter Notebook to test), \n",
    "# it will continue from the last sentence analyzed when resumed.\n",
    "\n",
    "# A counter and vectors are used to pass information to the arguments of analyze_sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d2dd96-5459-4188-9818-1081c2dccfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
